---
title: "On the inference of positive and negative interactions and their relation to abundance"
author: "Andrew J. Rominger"
output:
  pdf_document:
    fig_caption: yes
    keep_tex: no
    number_sections: no
csl: nature.csl
bibliography: RarePlusComMinus.bib
---

Why do rare species persist in ecosystems? Rare species seem to be at a disadvantage by pure probabilistic odds [@mcgill2005] and perhaps also from poorly adapted species-environment and species-species interactions [@hutchinson1961], though negative density-dependence may help rare species persist [@leigh2004; yenni2012]. The question of rarity and persistence remains thus unresolved.  In a recent paper, Calatayuda et al. [@calatayud2019] (CEA) infered species-species interaction networks from spatially replicated abundance data across many taxa and environments.  CEA found that rare species were associated with positive interactions whereas common species were associated with negative interactions, indicating that postive interactions, such as facilitation, may help rare species persist [@calatayud2019]. However, the use of abundance and co-occurence data to infer species interactions is difficult and often inaccurate [@freilich2018; carr2019; rajala2019]. This issue arrises in no small part becuase the underlying null models used to infer interactions themselves are known to have type I and II error problems in real world applications [@ulrich2010; @ladau2008; @ladau2017]. Here, I show that the finding of rare species being more associated with positive interactions as found by CEA [@calatayud2019] can be explained by statistical error in the inference of species interactions from abundance data. It would therefore not be supported to assign biological interpretations to these findings until more data can be brought to bear on the subject or interaction types and the persistence of rare species.



Things to discuss

- does the null model lead to poisson ssad's in the null permutations?




```{r setup}
library(knitr)
opts_chunk$set(echo = TRUE, cache = TRUE, 
               fig.width = 4, fig.height = 4, fig.align = 'center')

library(pika)
library(RarePlusComMinus)
library(parallel)
library(MASS)
library(socorro)
library(viridis)

# threading defaults
nthrd <- detectCores()
nthrd <- ifelse(round(nthrd * 0.8) >= nthrd - 1, nthrd - 1, round(nthrd * 0.8))
if(nthrd < 1) nthrd <- 1

# plotting defaults
parArgs <- list(mar = c(3, 3, 0, 0) + 0.5, mgp = c(1.5, 0.30, 0), tcl = -0.25)
cexDefault <- 1.4
lwdDefault <- 2
```


First we reproduce some of the key results of ref. [@calatayud2019], namely how abundance relates to positive and negative association networks.

```{r obs_data}
# load data from paper
data('abundace_matrices')

# clean it
obsdat <- lapply(abun.mat, function(x) {
    x <- ceiling(x)
    x <- x[rowSums(x) > 0, colSums(x) > 0]
    
    return(x)
})
```

```{r obs_plusMinus_comp}
commStats <- mclapply(obsdat, mc.cores = nthrd,
                      FUN = function(x) unlist(plusMinus(x)))

commStats <- as.data.frame(do.call(rbind, commStats))

# remove studies with too few plus or minus links
commStats[is.na(commStats$pos.rho.rho) | is.na(commStats$neg.rho.rho), ] <- NA
```

It should be noted that the authors of the original analysis [@calatayud2019] retained 326 studies after filtering, whereas I retain `r sum(!is.na(commStats$pos.wm))`. This may be in part because I removed any dataset for which there were fewer than three links in either the postive or negative networks, whereas the authors of the original analysis removed only those datasets with fewer than two links [@calatayud2019]. 

And now for the plot that reproduces Fig. 2 (b and c) from ref. [@calatayud2019].

```{r plusMinus_plotFuns, cache = FALSE}
# ----
# helper function for making fancy histograms
specialHist <- function(x, breaks, col, add = FALSE, ...) {
    h <- hist(x, breaks, plot = FALSE)

    if(!add) plot(range(h$breaks), range(h$counts), type = 'n', ...)

    rect(xleft = h$breaks[-length(h$breaks)], xright = h$breaks[-1], 
         ybottom = 0, ytop = h$counts, col = col)
}


# ----
# function to remake Fig 2(b-c)
fig2bc <- function(x, breaksRho, breaksWM, addxlab = TRUE) {
    # par(mar = rep(0, 4))
    # plot(1, type = 'n', axes = FALSE)
    plot.new()
    par(parArgs)
    par(cex = 1)
    
    fi <- split.screen(c(1, 2))
    
    # correlation differences
    screen(fi[1])
    
    par(parArgs)
    if(addxlab) {
        par(mar = parArgs$mar + c(0, 0, 0, -0.5))
        xlab <- 'Abundance-species degree differences\n(positive - negative)'
    } else {
        par(mar = parArgs$mar + c(-2.25, 0, 0, -0.5))
        xlab <- ''
    }
    
    specialHist(x$pos.rho.rho - x$neg.rho.rho, xlim = c(-2, 2),
                breaks = breaksRho, col = 'gray90',
                xlab = '', ylab = 'Number of assemblages')
    mtext(xlab, side = 1, line = 2.5)
    abline(v = 0, col = 'red', lty = 2, lwd = 2)
    
    
    # raw correlations
    fj <- split.screen(matrix(c(0.475 + 0.02, 0.975 + 0.02, 0.475, 0.975), nrow = 1), 
                        erase = FALSE)
    screen(fj, new = FALSE)
    
    par(parArgs)
    par(cex = 0.75)
    par(mgp = par('mgp') * par('cex'))
    
    specialHist(x$pos.rho.rho, xlim = c(-1, 1), ylim = c(0, 90),
                breaks = breaksRho / 2, col = hsv(0.65, alpha = 0.5),
                xlab = expression("Spearman's"~rho),
                ylab = '')
    specialHist(x$neg.rho.rho,
                breaks = breaksRho / 2, col = hsv(0, alpha = 0.5),
                add = TRUE)
    usr <- par('usr')
    points(usr[1] + c(0.2, 0.5) * diff(usr[1:2]), rep(usr[3] + 0.75 * diff(usr[3:4]), 2),
           cex = 3, bg = hsv(c(0.65, 0), alpha = 0.5), pch = 21)
    text(usr[1] + c(0.2, 0.5) * diff(usr[1:2]), rep(usr[3] + 0.75 * diff(usr[3:4]), 2),
         labels = c('+', '-'), cex = 2)
    
    
    # mean differences
    screen(fi[2])
    par(parArgs)
    if(addxlab) {
        par(mar = parArgs$mar + c(0, -1, 0, +0.5))
        xlab <- 'Abundance differences\n(positive - negative)'
    } else {
        par(mar = parArgs$mar + c(-2.25, -1, 0, +0.5))
        xlab <- ''
    }
    
    specialHist(x$pos.wm - x$neg.wm, xlim = c(-0.3, 0.3),
                breaks = breaksWM, col = 'gray90',
                xlab = '', ylab = '')
    mtext(xlab,
          side = 1, line = 2.5)
    abline(v = 0, col = 'red', lty = 2, lwd = 2)
    
    
    # raw means
    fk <- split.screen(matrix(c(0.475 - 0.04, 0.975 - 0.04, 0.475, 0.975), nrow = 1), 
                        erase = FALSE)
    screen(fk, new = FALSE)
    
    par(parArgs)
    par(cex = 0.75)
    par(mgp = par('mgp') * par('cex'))
    
    specialHist(x$pos.wm, xlim = c(0, 0.3),
                breaks = (breaksWM + 0.3) / 2, col = hsv(0.65, alpha = 0.5),
                xlab = 'Weighted mean abund.',
                ylab = '')
    specialHist(x$neg.wm,
                breaks = (breaksWM + 0.3) / 2, col = hsv(0, alpha = 0.5),
                add = TRUE)
    usr <- par('usr')
    points(usr[1] + (1 - c(0.5, 0.2)) * diff(usr[1:2]), 
           rep(usr[3] + 0.75 * diff(usr[3:4]), 2),
           cex = 3, bg = hsv(c(0.65, 0), alpha = 0.5), pch = 21)
    text(usr[1] + (1 - c(0.5, 0.2)) * diff(usr[1:2]), 
           rep(usr[3] + 0.75 * diff(usr[3:4]), 2),
         labels = c('+', '-'), cex = 2)
    
    close.screen(c(fi, fj, fk))
}
```

```{r obs_plusMinus_plot, fig.width = 7.5, fig.height = 4, cache = FALSE}
fig2bc(commStats, breaksRho = seq(-2, 2, by = 1/5), 
       breaksWM = seq(-0.3, 0.3, by = 0.1/3))
```


```{r fig2-estimates}
# estimate number of assembledges suggested by Fig 2c; number refer to arbitrary
# pixle coordinates from the figure rescaled to the y-axis units

y0 <- 517
ys <- c(173, 345)

r <- 220 / mean((y0 - ys) * 1:2)

yblu <- c(234, 399, 478, 498, 507, 507, 509, rep(512, 5))
yred <- c(498, 375, 403, 419, 467, 482, 505)

fig2est <- r * (sum((y0 - yblu)) + sum((y0 - yred)))
```

It should be noted that our inset figure of mean weighted abundances differs from the original paper [@calatayud2019] in that their y-axis ranges from 0 to 220, while ours ranges from 0 to 120; we suspected the original authors mislabled their axis, because the scale as presented would suggest over `r 100 * floor(fig2est / 100)` assembledges, while the number should be 326.  Rescaling their axis to range from 0 to 120 brings this estimate more in line with the reported number of assembledges.

Now we explore the shape of the spatial abundance patters in the real data provided by ref. [@calatayud2019].


```{r ssad_comp}
summStats <- mclapply(obsdat, mc.cores = nthrd, FUN = function(x) {
    nbInfo <- nbFit(x)
    cbind(nsite = nrow(x), nspp = ncol(x), J = sum(x), nbInfo)
})

summStats <- data.frame(study = rep(names(obsdat), sapply(summStats, nrow)),
                        do.call(rbind, summStats))

# remove failed optims
# summStats <- summStats[!is.na(summStats$size), ]

# looks like an optim bug around size = 100, remove it
# summStats[round(summStats$size) == 100, c('size', 'mu', 'loglik')] <- NA
```

```{r ssad_fit_plot, cache = FALSE, eval = FALSE}
# nbAIC <- 2 * (2 - summStats$loglik)
# poAIC <- 2 * (1 - summStats$poisLogLik)

par(parArgs)
plot(summStats$mu, summStats$size,
     # col = c('red', 'black')[as.integer(nbAIC < poAIC + 2) + 1],
     log = 'xy', xaxt = 'n', yaxt = 'n',
     xlab = expression(mu), ylab = expression(k))
logAxis(1:2, expLab = TRUE)
# legend('topleft', legend = c('NB sufficient', 'Pois better'),
#        col = c('black', 'red'), pch = 1, bty = 'n')
```

```{r ssad_plot, fig.width = 5, fig.height = 5, cache = FALSE, eval = FALSE}
# helper funciton for easy log-log ploits
llplot <- function(x, y, expLab = TRUE, ...) {
    plot(x, y, xaxt = 'n', yaxt = 'n', ...)
    logAxis(1:2, expLab = expLab)
}

layout(matrix(1:4, ncol = 2, byrow = TRUE))
par(parArgs)

llplot(summStats$nsite, summStats$J, log = 'xy',
     xlab = 'Number of sites', ylab = 'Number of individuals', 
       col = quantCol(summStats$nspp, viridis(40), 'log'))
llplot(summStats$J, summStats$nspp, log = 'xy',
     xlab = 'Number of individuals', ylab = 'Number of species', 
       col = quantCol(summStats$nspp, viridis(40), 'log'))
llplot(summStats$abund / summStats$nsite, summStats$mu, log = 'xy', 
       xlab = 'Mean abund. per site', ylab = expression(mu), 
       col = quantCol(summStats$nspp, viridis(40), 'log'))
llplot(summStats$abund / summStats$J, summStats$size, log = 'xy', 
       xlab = 'Relative abundance', ylab = expression(k), 
       col = quantCol(summStats$nspp, viridis(40), 'log'))
```

We can also get a sense for the SADs of each assembledge

```{r sad_comp}
mods <- c('fish', 'plnorm', 'tnegb')
sadStats <- mclapply(obsdat, mc.cores = nthrd, FUN = function(x) {
    x <- colSums(x)
    s <- fitSAD(x, mods)
    
    i <- which.min(sapply(s, AIC))
    o <- s[[i]]$MLE
    if(i == 1) o <- c(o, NA)
    
    o <- c(i, o)
    names(o) <- NULL
    
    return(o)
})

sadStats <- as.data.frame(do.call(rbind, sadStats))
names(sadStats) <- c('mod', 'par1', 'par2')
sadStats$mod <- mods[sadStats$mod]

# limit to only those sites that produced good networks
sadStats <- sadStats[rownames(sadStats) %in% 
                         rownames(commStats[!is.na(commStats$pos.n), ]), ]
```

We'll make linear models of the SSAD relationships to sample from in addition to sampling from the SAD

```{r ssad_lm}
# indBySiteMod <- lm(log(summStats$J) ~ log(summStats$nsite))
# data for linear model of k, excluding sites that didn't produce a good network
dat4k <- with(summStats[summStats$study %in%
                            rownames(commStats[!is.na(commStats$pos.n), ]), ],
              data.frame(logk = log(size),
                         loga = log(abund / J),
                         logS = log(nspp))
)

# kByRelSppMod <- lm(logk ~ loga + logS, data = dat4k)
kMod <- lm(logk ~ loga, data = dat4k[is.finite(dat4k$logk), ])

# function to generate k values from input number of species and abundances
# kfunSpp <- function(nspp, abund) {
#     J <- sum(abund)
#     exp(predict(kByRelSppMod, newdata = data.frame(loga = log(abund / J),
#                                                    logS = log(nspp))) +
#             rnorm(nspp, sd = summary(kByRelSppMod)$sigma))
# }

kfun <- function(nspp, abund) {
    J <- sum(abund)
    
    exp(predict(kMod, newdata = data.frame(loga = log(abund / J))) +
            rnorm(nspp, sd = summary(kMod)$sigma))
}
```


Now we can do a simulation where we make slightly more than `r sum(!is.na(commStats$pos.wm))` simulated communities (slightly more because some will be rejected) and see how their positive and negative associate networks look.

```{r sim_plusMinus_comp}
# number of simulations to run
nsim <- round(1.25 * sum(!is.na(commStats$pos.wm)))

# numbers of sites and species to sample from
# note: only using those sites that produced good networks
nsitenspp <- unique(summStats[
    summStats$study %in% rownames(commStats[!is.na(commStats$pos.n), ]), 
    c('study', 'nsite', 'nspp')])

# loop over simulation replicates
# simPMData <- simPlusMinus(nsitenspp = nsitenspp, sadStats = sadStats, mcCores = nthrd, 
#                           ssadType = 'nbinom', kfun = kfunSpp, nsim = nsim)
simPMData <- simPlusMinus(nsitenspp = nsitenspp, sadStats = sadStats, mcCores = nthrd, 
                          ssadType = 'nbinom', kfun = kfun, nsim = nsim)
```

```{r sim_plusMinus_plot, fig.width = 7.5, fig.height = 4, cache = FALSE}
wmmax <- ceiling(max(simPMData$pos.wm, simPMData$neg.wm, na.rm = TRUE) * 9) / 3

fig2bc(simPMData, breaksRho = seq(-2, 2, by = 1/5), 
       breaksWM = seq(-wmmax, wmmax, by = 0.1/3))
```


Now we want to figure out if this is specifically because of the shape of the SSAD (i.e. negative binomial) or if a spatially unclustered SSAD would also yield this result. We do this by modeling the SSAD with a Poisson distribution and compare

```{r sim_pois_plusMinus_comp}
# loop over simulation replicates
simPMDataPois <- simPlusMinus(nsitenspp = nsitenspp, sadStats = sadStats, 
                              mcCores = nthrd, 
                              ssadType = 'pois', kfun = NULL, nsim = nsim)
```

```{r sim_pois_plusMinus_plot, fig.width = 7.5, fig.height = 4, cache = FALSE}
wmmax <- ceiling(max(simPMDataPois$pos.wm, simPMDataPois$neg.wm, na.rm = TRUE) * 9) / 3

fig2bc(simPMDataPois, breaksRho = seq(-2, 2, by = 1/5), 
       breaksWM = seq(-wmmax, wmmax, by = 0.1/3))
```

And lastly we might be interested in whether we need to use quantities from the dat so much. We might instead imagine one arbitrary SAD and one arbitrary negative binomial SSAD and see if qualitatively similar results are found.

```{r, sim_simple_nb_plusMinus_comp}
oneK <- 0.05
b <- 0.01
nsiteSimp <- 20
nsppSimp <- 100
nsimSimp <- nsim

simPMSimpNB <- simpleSim(nsiteSimp, nsppSimp, nthrd, sadfun = function(n) rfish(n, b), 
                         ssadfun = function(n, mu) rnbinom(n, oneK, mu = mu), 
                         nsim = nsimSimp)
```

```{r, sim_simple_pois_plusMinus_comp}
simPMSimpPo <- simpleSim(nsiteSimp, nsppSimp, nthrd, sadfun = function(n) rfish(n, b), 
                         ssadfun = function(n, mu) rpois(n, lambda = mu), 
                         nsim = nsimSimp)
```

Putting all plots together
```{r foo_plot, fig.width = 7.5, fig.height = 7.5, cache = FALSE}
split.screen(c(2, 1))

screen(1)
fig2bc(simPMSimpNB, breaksRho = seq(-2, 2, by = 1/5), 
       breaksWM = seq(-0.3, 0.3, by = 0.1/3), addxlab = FALSE)

screen(2)
fig2bc(simPMSimpPo, breaksRho = seq(-2, 2, by = 1/5), 
       breaksWM = seq(-0.3, 0.3, by = 0.1/3), addxlab = FALSE)

close.screen(all.screens = TRUE)
```


```{r ssad_perm_comp, eval = FALSE}
simNBPerm <- ssadSim(30, 50, nthrd, function(n) {rfish(n, 0.01)},
                     function(n, mu) {rnbinom(n, 0.05, mu = mu)}, nsim = 50, B = 499)

hist(simNBPerm$size)
hist(simNBPerm$mu)
hist(simNBPerm$dAIC)
```

# References

